{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Azure\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Integrasi dengan PostgreSQL\n",
    "import psycopg2\n",
    "from psycopg2 import pool \n",
    "import ast\n",
    "import pgvector\n",
    "import math\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to PostreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n"
     ]
    }
   ],
   "source": [
    "host = \"c-skillup-vector.hh3bwvk75ljfl6.postgres.cosmos.azure.com\"\n",
    "dbname = \"skillup-citus\"\n",
    "user = \"citus\"\n",
    "password = \"SkillUp123\"\n",
    "sslmode = \"require\"\n",
    "\n",
    "conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(host, user, dbname, password, sslmode)\n",
    "\n",
    "postgreSQL_pool = None\n",
    "if (not postgreSQL_pool):\n",
    "    print(\"Connection pool created successfully\")\n",
    "    postgreSQL_pool = psycopg2.pool.SimpleConnectionPool(1, 20,conn_string)\n",
    "    \n",
    "    conn = postgreSQL_pool.getconn()\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://skillupllm.openai.azure.com/openai/deployments/SkillUp-Embedding/embeddings?api-version=2024-02-01\"\n",
    "\n",
    "headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'api-key': '8575d0680b2e48599a9058bf62713335'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Hasil Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    # Create table to store embeddings and metadata\n",
    "    table_create_command = \"\"\"\n",
    "    CREATE TABLE data_scrapping (\n",
    "        id bigserial primary key, \n",
    "        company_names text,\n",
    "        job_titles text,\n",
    "        posted_on date,\n",
    "        job_details text,\n",
    "        skill text,\n",
    "        images text,\n",
    "        type_location text,\n",
    "        location text,\n",
    "        embedding vector(1536)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(table_create_command)\n",
    "    # cursor.close()\n",
    "    conn.commit()\n",
    "except Exception as e :\n",
    "    print(\"Table Exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"c-skillup-vector.hh3bwvk75ljfl6.postgres.cosmos.azure.com\"\n",
    "dbname = \"skillup-citus\"\n",
    "user = \"citus\"\n",
    "password = \"SkillUp123\"\n",
    "sslmode = \"require\"\n",
    "\n",
    "conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(host, user, dbname, password, sslmode)\n",
    "\n",
    "postgreSQL_pool = None\n",
    "if (not postgreSQL_pool):\n",
    "    print(\"Connection pool created successfully\")\n",
    "    postgreSQL_pool = psycopg2.pool.SimpleConnectionPool(1, 20,conn_string)\n",
    "    \n",
    "    conn = postgreSQL_pool.getconn()\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def select_data(cursor, conn):\n",
    "    # Tentukan path folder\n",
    "    folder_path = 'D:\\Codelabs\\Kompetisi\\AIC Compfest\\Projek'\n",
    "\n",
    "    # Ambil semua nama file dengan ekstensi .csv di dalam folder\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    for csv in csv_files:\n",
    "        print(\"Nama File : \",csv)\n",
    "        df_data = pd.read_csv(str(csv))\n",
    "        df_data.fillna(\"\")\n",
    "        print(\"Jumlah Data : \",df_data.shape)\n",
    "        # Terapkan fungsi ke kolom 'Posted On'\n",
    "        df_data['Posted On'] = df_data['Posted On'].apply(convert_posted_on)\n",
    "        df_data['all_text'] = df_data['Job Titles'] + ' ' + df_data['Job Details'] + ' ' + df_data['Skill']\n",
    "        df_data['all_text'] = df_data['all_text'].str.replace('\\n', '', regex=False)\n",
    "        df_data['Text Embed'] = df_data['all_text'].apply(embed_text)\n",
    "        df_data.dropna(subset=\"Text Embed\", inplace=True)\n",
    "        display(df_data['Text Embed'])\n",
    "        store_data(cursor, conn, df_data)\n",
    "\n",
    "def embed_text(title) :\n",
    "    try:\n",
    "        payload = json.dumps({\"input\": title})\n",
    "        print(\"Ini payload : \",payload)\n",
    "        # Send a POST request and get the query embedding\n",
    "        responses = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "        print(responses.json()['data'][0]['embedding'])\n",
    "        query_embedding = responses.json()['data'][0]['embedding']\n",
    "        return query_embedding\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def convert_posted_on(posted_on):\n",
    "    # Tangani kasus yang ada\n",
    "    if 'Reposted' in posted_on:\n",
    "        # Ambil minggu dari \"Reposted\" jika ada\n",
    "        weeks = int(posted_on.split()[1])\n",
    "        return datetime.now() - timedelta(weeks=weeks)\n",
    "    elif 'week ago' in posted_on:\n",
    "        weeks = int(posted_on.split()[0])\n",
    "        return datetime.now() - timedelta(weeks=weeks)\n",
    "    elif 'weeks ago' in posted_on:\n",
    "        weeks = int(posted_on.split()[0])\n",
    "        return datetime.now() - timedelta(weeks=weeks)\n",
    "    elif 'month ago' in posted_on:\n",
    "        months = int(posted_on.split()[0])\n",
    "        return datetime.now() - timedelta(weeks=months*4)  # Estimasi 1 bulan = 4 minggu\n",
    "    elif 'day ago' in posted_on:\n",
    "        days = int(posted_on.split()[0])\n",
    "        return datetime.now() - timedelta(days=days)\n",
    "    elif 'hours ago' in posted_on:\n",
    "        hours = int(posted_on.split()[0])\n",
    "        return datetime.now() - timedelta(hours=hours)\n",
    "    else:\n",
    "        return datetime.now()  # Jika tidak ada format yang dikenali, kembalikan tanggal sekarang\n",
    "\n",
    "def store_data(cursor, conn, df_data):\n",
    "    data_list = [\n",
    "        (\n",
    "            row['Company Names'], \n",
    "            row['Job Titles'], \n",
    "            row['Posted On'], \n",
    "            row['Job Details'], \n",
    "            row['Skill'], \n",
    "            row['Images'], \n",
    "            row['Type Location'], \n",
    "            row['Locations'],\n",
    "            row['Text Embed']\n",
    "        ) \n",
    "        for index, row in df_data.iterrows()\n",
    "    ]\n",
    "\n",
    "    execute_values(cursor, \n",
    "        \"INSERT INTO data_scrapping (company_names, job_titles, posted_on, job_details, skill, images, type_location, location, embedding) VALUES %s\", \n",
    "        data_list\n",
    "    )\n",
    "\n",
    "    # Commit setelah melakukan insert\n",
    "    conn.commit()\n",
    "\n",
    "select_data(cursor, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_category = \"Website\"\n",
    "payload = json.dumps({\"input\": job_category})\n",
    "# Send a POST request and get the query embedding\n",
    "responses = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "query_embedding = responses.json()['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Execute the SQL query to retrieve relevant data\n",
    "    cursor.execute(\"\"\"\n",
    "                    SELECT company_names, job_titles, posted_on, job_details, skill, images, type_location, location,\n",
    "                    (1 - (embedding <=> %s)) as similarity FROM data_scrapping \n",
    "                    WHERE 1 - (embedding <=> %s) > %s\n",
    "                    ORDER BY similarity DESC\n",
    "                    \"\"\", (str(query_embedding), str(query_embedding), str(0.1)))\n",
    "except Exception as e:\n",
    "    print(\"error : \", e)\n",
    "\n",
    "# Fetch all the data\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# Get the column names from the cursor description\n",
    "column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tren Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membersihkan job_titles\n",
    "def clean_job_title(title):\n",
    "    title = str(title).lower()\n",
    "    if \"science\" in title.lower():\n",
    "        title = title.lower().replace(\"science\", \"scientist\")\n",
    "    if \"engineering\" in title.lower():\n",
    "        title = title.lower().replace(\"engineering\", \"engineer\")\n",
    "    if \"analytics\" in title.lower():\n",
    "        title = title.lower().replace(\"analytics\", \"analyst\")\n",
    "    if \"ds\" in title.lower():\n",
    "        title = title.lower().replace(\"ds\", \"data scientist\")\n",
    "    if \"front end\" in title.lower():\n",
    "        title = title.lower().replace(\"front end\", \"frontend\")\n",
    "    if \"(\" in title.lower():\n",
    "        title = title.lower().replace(\"(\", \",\")\n",
    "    if \"lead\" in title.lower():\n",
    "        title = title.lower().replace(\"lead\", \"\")\n",
    "    if \"senior\" in title.lower():\n",
    "        title = title.lower().replace(\"senior\", \"\")\n",
    "    if \"remote\" in title.lower():\n",
    "        title = title.lower().replace(\"remote\", \"\")\n",
    "    if \"sr.\" in title.lower():\n",
    "        title = title.lower().replace(\"sr.\", \"\")\n",
    "    # if \"data\" in title.lower():\n",
    "    #     title = title.lower().replace(\"data\", \"\")\n",
    "    # Menghapus kata 'intern', 'internship', dan 'freelance'\n",
    "    title = re.sub(r'\\b(intern(ship)?|freelance)\\b', '', title, flags=re.IGNORECASE)\n",
    "    title = re.sub(r'[()]', '', title)\n",
    "            \n",
    "    return title.strip()\n",
    "\n",
    "# Menerapkan fungsi ke kolom 'Job Title'\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.drop_duplicates(subset=['company_names','job_titles','skill','type_location','location'])\n",
    "df['job_titles'] = df['job_titles'].apply(clean_job_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=\"8575d0680b2e48599a9058bf62713335\",  \n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=\"https://skillupllm.openai.azure.com/\"\n",
    ")\n",
    "    \n",
    "deployment_name = 'SkillUp-4o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_final = '''\n",
    "ini adalah list job title Backend dari hasil pengambilan data di linkedin. berikan saya 5 job yang paling banyak dicari\n",
    "'''+str(df['job_titles'].to_list())+'''\n",
    "\n",
    "Terdapat aturan yang harus kamu patuhi :\n",
    "1. Hasil keluaran wajib dalam format seperti contoh di bawah :\n",
    "[\n",
    " {'job_title':'Nama Job','total':45},\n",
    " {'job_title':'Nama Job','total':17},\n",
    " {'job_title':'Nama Job','total':11},\n",
    " {'job_title':'Nama Job','total':10},\n",
    " {'job_title':'Nama Job','total':6}\n",
    "]\n",
    "2. Tidak boleh ada keluaran lain selain pada poin 1\n",
    "3. Jangan sampai ada nama tempat di hasilnya, betul betul hanya nama job\n",
    "4. Jangan sampe ada yang double job misal 'data warehouse data engineer'\n",
    "5. Pekerjaan yang dicari adalah yang berkaitan dengan '''+job_category+'''\n",
    "6. Jangan sampai ada nama job yang double, misal sebelumnya sudah ada \"data engineer\" namun di nama job berikutnya terdapat \"it data engineer\" cukup satu saja \"data engineer\"\"'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'job_title': 'web developer', 'total': 7}, {'job_title': 'fullstack web developer', 'total': 5}, {'job_title': 'backend developer', 'total': 5}, {'job_title': 'software engineer', 'total': 5}, {'job_title': 'frontend developer', 'total': 4}]\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(model=deployment_name, messages=[{\"role\": \"user\", \"content\": prompt_final}], stream=False, max_tokens=2000, temperature=0 )\n",
    "result = response.choices[0].message.content\n",
    "\n",
    "# Membersihkan string dan mengganti tanda kutip tunggal dengan kutip ganda\n",
    "cleaned_string = result.replace(\"'\", '\"').replace(\"\\n\", \"\").replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "# Mengonversi string menjadi JSON\n",
    "json_data = json.loads(cleaned_string)\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(json_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compfestaic2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
